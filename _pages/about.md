---
permalink: /
title: "About Me"
excerpt: "About Me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
classes: "about-page"
---

I'm a Ph.D candidate at <a href="https://mli.kaist.ac.kr/" target="_blank" style="color: black;">Machine Learning and Intelligence Lab (MLILAB)</a> at <a href="
https://www.kaist.ac.kr/en/" target="_blank" style="color: black;">KAIST</a> in South Korea, advised by <a href="https://scholar.google.com/citations?user=UWO1mloAAAAJ&hl=ko&oi=ao" target="_blank" style="color: black;">Prof. Eunho Yang</a>.

My recent research interests focus on
        <span style="color: #1A73E8; font-weight: bold;">(i) self-improving large multi-modal agents for generalization</span>  (closely working with <a href="https://scholar.google.com/citations?user=1R3XgHQAAAAJ&hl=en" target="_blank" style="color: black;"> Ninareh Mehrabi </a> <img src="https://upload.wikimedia.org/wikipedia/commons/a/a9/Amazon_logo.svg" alt="Amazon" width="50" style="vertical-align: middle; margin-left: 5px;  top: 5px;"> and  <a href="https://scholar.google.com.au/citations?user=WnWN4NkAAAAJ&hl=en" target="_blank" style="color: black;"> Sina Shaham</a> <img src="https://logodownload.org/wp-content/uploads/2021/10/meta-logo-1.png" alt="Meta" width="50" style="vertical-align: middle; margin-left: 5px;position: top: -2px;">)
        and 
        <span style="color: #1A73E8; font-weight: bold;">(ii) addressing hallucination in multi-modal large language models </span>. 
        I am also interested in developing 
        <span style="color: #1A73E8; font-weight: bold;">(iii) robust fine-tuning methods for vision-language models</span> 
        to ensure reliable deployment in real-world applications.
Previously, my work centered on understanding and improving model robustness across diverse modalities, including 2D and 3D vision, and multi-modal models. 

<!---
My interests include, but are not limited to, ***understanding and enhancing model robustness*** across diverse modalities such as 2D & 3D vision, vision-language, and multi-modal models. 

Recently, my research has focused on ***robust learning/fine-tuning methods for large vision-language and multi-modal autoregressive models***, aimed at improving adaptability and resilience to diverse data distributions and task variations, thereby enhancing performance consistency in complex, real-world scenarios. 
-->

**Please feel free to contact me if you are interested in potential collaborations!** &nbsp; <a href="https://www.linkedin.com/in/yeonsung-jung-a50015213/" target="_blank" style="color: #1E90FF">
    <img src="https://cdn-icons-png.flaticon.com/512/174/174857.png" alt="LinkedIn" width="15" height="15"> LinkedIn </a>



<!---
My research interest falls into enhancing the understanding of unstructured/video data modalities through the guidance of large language models. With these goals in mind, my recent focus has been on linking diverse modalities into the core of large language model **through the lens of graph-structured knowledge**, *e.g.* object graphs (3D vision), knowledge graphs (natural language), and scene graphs (video). In this endeavor, I work on building algorithms that leverage relational information of data therein, **revisiting real-world problems within a graph-based framework to provide a structured understanding of complex data modalities** in large language models.
- Multimodal Large language models: Generation and Comprehension
- Compositional Generalization (Object-centric Learning)
- Graph-driven Modal Understanding
-->


<!---**Learning on 3D Vision**\\
My primary research interest in 3D vision falls into two branches following: 1) **Cross-modal 3D understanding**. It aims to harness the power of auxiliary data modalities for an in-depth comprehension of complex 3D data. Currently, I'm working on open-vocabulary 3D scene segmentation with object-relational graphs leveraging recent language foundation models' capabilities. 2) **Sim-to-real adaptation for 3D data**. My recent research efforts have been dedicated to narrowing the domain gap between synthetic and real-world 3D data. Ranging from developing adaptation strategies to curating 3D photorealistic datasets, my recent objective is to facilitate successful sim-to-real transfer across a broad range of 3D vision tasks.
-->
## Conference Publications
- **<font size="4">LANTERN: Accelerating Visual Autoregressive Models with Relaxed Speculative Decoding</font>** <a href="https://arxiv.org/abs/2410.03355" target="_blank" style="color: #1E90FF">[paper]</a> \\
Doohyuk Jang\*, Sihwan Park\*, June Yong Yang, **Yeonsung Jung**, Jihun Yun, Souvik Kundu, Sung-Yub Kim†, Eunho Yang†\\
<span style="color:darkred">**ICLR**</span> 2025

- **<font size="4">A Simple Remedy for Dataset Bias via Self-Influence: A Mislabeled Sample Perspective</font>** <a href="https://arxiv.org/abs/2411.00360" target="_blank" style="color: #1E90FF">[paper]</a> \\
**Yeonsung Jung\***, Jaeyun Song\*, June Yong Yang, Jin-Hwa Kim, Sung-Yub Kim, Eunho Yang \\
<span style="color:darkred">**NeurIPS**</span> 2024

- **<font size="4">PruNeRF: Segment-Centric Dataset Pruning via 3D Spatial Consistency</font>** <a href="https://proceedings.mlr.press/v235/jung24b.html" target="_blank" style="color: #1E90FF">[paper]</a> \\
**Yeonsung Jung**, Heecheol Yun, Joonhyung Park, Jin-Hwa Kim†, Eunho Yang† \\
<span style="color:darkred">**ICML**</span> 2024

- **<font size="4">Fighting Fire with Fire: Contrastive Debiasing without Bias-free Data via Generative Bias-transformation</font>** <a href="https://proceedings.mlr.press/v202/jung23b.html" target="_blank" style="color: #1E90FF">[paper]</a> \\
**Yeonsung Jung**, Hajin Shim, June Yong Yang, Eunho Yang \\
<span style="color:darkred">**ICML**</span> 2023

- **<font size="4">Scalable Anti-TrustRank with Qualified Site-level Seeds for Link-based Web Spam Detection</font>** <a href="https://dl.acm.org/doi/pdf/10.1145/3366424.3385773" target="_blank" style="color: #1E90FF">[paper]</a> \\
Joyce Jiyoung Whang, **Yeonsung Jung**, Seonggoo Kang, Dongho Yoo, Inderjit S. Dhillon \\
<span style="color:darkred">**The Web Conf. Workshop**</span> on CyberSafety: Computational Methods in Online Misbehavior 2024

- **<font size="4">Fast Asynchronous Anti-TrustRank for Web Spam Detection</font>** <a href="https://proceedings.mlr.press/v202/jung23b/jung23b.pdf" target="_blank" style="color: #1E90FF">[paper]</a> \\
Joyce Jiyoung Whang, **Yeonsung Jung**, Inderjit S. Dhillon, Seonggoo Kang, Jungmin Lee \\
<span style="color:darkred">**WSDM Workshop**</span> on MIS2: Misinformation and Misbehavior Mining on the Web 2024

## Preprints
- **<font size="4">Augmentation-Driven Metric for Balancing Preservation and Modification in Text-Guided Image Editing</font>** <a href="https://arxiv.org/abs/2410.11374" target="_blank" style="color: #1E90FF">[paper]</a> \\
Yoonjeon Kim\*, Soohyun Ryu\*, **Yeonsung Jung**, Hyunkoo Lee, Joowon Kim, June Yong Yang, Jaeryong Hwang, Eunho Yang \\
<span style="color:darkred">**under review**</span>

- **<font size="4">Playing the Fool: Jailbreaking Large Language Models with Out-of-Distribution Strategies</font>** \\
Joonhyun Jeong, Seyun Bae, **Yeonsung Jung**, Jaeryong Hwang, Eunho Yang \\
<span style="color:darkred">**under review**</span>

- **<font size="4">	MeZO-A<sup>3</sup>dam: Memory-efficient Zeroth-order Adam with Adaptivity Adjustments for Fine-tuning LLMs</font>** \\
Sihwan Park\*, Jihun Yun\*, Sung-Yub Kim, June Yong Yang, **Yeonsung Jung**, Souvik Kundu, Kyungsu Kim, Eunho Yang \\
<span style="color:darkred">**under review**</span>

- **<font size="4">3D Scene Decomposition Under Occlusion via Multi-View-Aware Inpainting</font>** \\
Heecheol Yun, **Yeonsung Jung**, Eunho Yang \\
<span style="color:darkred">**under review**</span>

## Work Experiences
- Research Intern, **NAVER**, Seongnam, South Korea. (July 2019 - Sept. 2019)
  - Improve searching performance through click graph neural networks.

<!---
## Projects
- Sub-task generation based point/regional Out-Of-Distribution detection, **Samsung Electronics**, <font size="3">Sep. 2020 - Sep. 2025</font>
- Predicting graph properties with few labels using Graph Neural Networks, **Samsung Electronics**, <font size="3">Sep. 2020 - Sep. 2025</font>
- Machine learning model for the prediction of Hypoxaemia during Endoscopic Retrograde Cholangiopancreatography, **Yonsei Severance Hospital**, <font size="3">Mar. 2020 - Jun. 2020</font>
    - Published in [Yonsei Medical Journal](https://ymj.kr/DOIx.php?id=10.3349/ymj.2022.0381)
-->

## Acamdeic Services
- Conference Reviewer
    - Neural Information Processing Systems (NeurIPS)
    - International Conference on Machine Learning (ICML)
    - International Conference on Learning Representations (ICLR)
    - Computer Vision and Pattern Recognition (CVPR)
    - Artificial Intelligence and Statistics (AISTATS)
    
<!---
  - Computer Vision and Pattern Recognition (CVPR)
  - AAAI Conference on Artificial Intelligence (AAAI)
  - International Conference on Acoustics, Speech, and Signal Processing (ICASSP)
  - Learning on Graphs (LoG)
- Journal Reviewer
  - Transactions on Neural Networks and Learning Systems (TNNLS)
-->

